{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 1054,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009487666034155597,
      "grad_norm": 16956.0234375,
      "learning_rate": 0.000299146110056926,
      "loss": 3.1786,
      "step": 10
    },
    {
      "epoch": 0.018975332068311195,
      "grad_norm": 17460.625,
      "learning_rate": 0.0002981973434535104,
      "loss": 3.3635,
      "step": 20
    },
    {
      "epoch": 0.028462998102466792,
      "grad_norm": 15505.400390625,
      "learning_rate": 0.00029724857685009483,
      "loss": 3.1043,
      "step": 30
    },
    {
      "epoch": 0.03795066413662239,
      "grad_norm": 13139.1611328125,
      "learning_rate": 0.0002962998102466793,
      "loss": 3.1726,
      "step": 40
    },
    {
      "epoch": 0.04743833017077799,
      "grad_norm": 19630.619140625,
      "learning_rate": 0.0002953510436432637,
      "loss": 3.0462,
      "step": 50
    },
    {
      "epoch": 0.056925996204933584,
      "grad_norm": 26639.7890625,
      "learning_rate": 0.0002944022770398482,
      "loss": 2.9535,
      "step": 60
    },
    {
      "epoch": 0.06641366223908918,
      "grad_norm": 22922.875,
      "learning_rate": 0.0002934535104364326,
      "loss": 3.4645,
      "step": 70
    },
    {
      "epoch": 0.07590132827324478,
      "grad_norm": 27970.537109375,
      "learning_rate": 0.00029250474383301706,
      "loss": 3.184,
      "step": 80
    },
    {
      "epoch": 0.08538899430740038,
      "grad_norm": 19267.205078125,
      "learning_rate": 0.0002915559772296015,
      "loss": 2.8727,
      "step": 90
    },
    {
      "epoch": 0.09487666034155598,
      "grad_norm": 23281.58984375,
      "learning_rate": 0.00029060721062618594,
      "loss": 3.0028,
      "step": 100
    },
    {
      "epoch": 0.10436432637571158,
      "grad_norm": 40149.27734375,
      "learning_rate": 0.0002896584440227704,
      "loss": 3.0443,
      "step": 110
    },
    {
      "epoch": 0.11385199240986717,
      "grad_norm": 16625.962890625,
      "learning_rate": 0.0002887096774193548,
      "loss": 2.9115,
      "step": 120
    },
    {
      "epoch": 0.12333965844402277,
      "grad_norm": 26792.09765625,
      "learning_rate": 0.00028776091081593924,
      "loss": 2.9058,
      "step": 130
    },
    {
      "epoch": 0.13282732447817835,
      "grad_norm": 25105.55078125,
      "learning_rate": 0.0002868121442125237,
      "loss": 2.8924,
      "step": 140
    },
    {
      "epoch": 0.14231499051233396,
      "grad_norm": 23383.95703125,
      "learning_rate": 0.0002858633776091081,
      "loss": 2.6898,
      "step": 150
    },
    {
      "epoch": 0.15180265654648956,
      "grad_norm": 33937.55078125,
      "learning_rate": 0.0002849146110056926,
      "loss": 2.9716,
      "step": 160
    },
    {
      "epoch": 0.16129032258064516,
      "grad_norm": 38101.0703125,
      "learning_rate": 0.000283965844402277,
      "loss": 2.9176,
      "step": 170
    },
    {
      "epoch": 0.17077798861480076,
      "grad_norm": 37649.0703125,
      "learning_rate": 0.0002830170777988615,
      "loss": 2.9507,
      "step": 180
    },
    {
      "epoch": 0.18026565464895636,
      "grad_norm": 42825.28125,
      "learning_rate": 0.0002820683111954459,
      "loss": 2.9079,
      "step": 190
    },
    {
      "epoch": 0.18975332068311196,
      "grad_norm": 29026.20703125,
      "learning_rate": 0.0002811195445920303,
      "loss": 3.3187,
      "step": 200
    },
    {
      "epoch": 0.19924098671726756,
      "grad_norm": 45726.84375,
      "learning_rate": 0.00028017077798861477,
      "loss": 2.7908,
      "step": 210
    },
    {
      "epoch": 0.20872865275142316,
      "grad_norm": 29462.669921875,
      "learning_rate": 0.00027922201138519924,
      "loss": 2.8254,
      "step": 220
    },
    {
      "epoch": 0.21821631878557876,
      "grad_norm": 31086.806640625,
      "learning_rate": 0.00027827324478178365,
      "loss": 2.9059,
      "step": 230
    },
    {
      "epoch": 0.22770398481973433,
      "grad_norm": 39775.58984375,
      "learning_rate": 0.0002773244781783681,
      "loss": 2.7156,
      "step": 240
    },
    {
      "epoch": 0.23719165085388993,
      "grad_norm": 42012.765625,
      "learning_rate": 0.00027637571157495253,
      "loss": 2.7397,
      "step": 250
    },
    {
      "epoch": 0.24667931688804554,
      "grad_norm": 24940.931640625,
      "learning_rate": 0.000275426944971537,
      "loss": 2.6114,
      "step": 260
    },
    {
      "epoch": 0.25616698292220114,
      "grad_norm": 35302.49609375,
      "learning_rate": 0.0002744781783681214,
      "loss": 2.9444,
      "step": 270
    },
    {
      "epoch": 0.2656546489563567,
      "grad_norm": 39281.87109375,
      "learning_rate": 0.00027352941176470583,
      "loss": 2.5803,
      "step": 280
    },
    {
      "epoch": 0.27514231499051234,
      "grad_norm": 38651.78125,
      "learning_rate": 0.0002725806451612903,
      "loss": 2.5897,
      "step": 290
    },
    {
      "epoch": 0.2846299810246679,
      "grad_norm": 38852.13671875,
      "learning_rate": 0.0002716318785578747,
      "loss": 2.893,
      "step": 300
    },
    {
      "epoch": 0.29411764705882354,
      "grad_norm": 39935.6875,
      "learning_rate": 0.0002706831119544592,
      "loss": 2.7431,
      "step": 310
    },
    {
      "epoch": 0.3036053130929791,
      "grad_norm": 31121.091796875,
      "learning_rate": 0.00026973434535104365,
      "loss": 2.7586,
      "step": 320
    },
    {
      "epoch": 0.31309297912713474,
      "grad_norm": 38535.2265625,
      "learning_rate": 0.00026878557874762806,
      "loss": 2.3313,
      "step": 330
    },
    {
      "epoch": 0.3225806451612903,
      "grad_norm": 50524.06640625,
      "learning_rate": 0.00026783681214421253,
      "loss": 2.7304,
      "step": 340
    },
    {
      "epoch": 0.33206831119544594,
      "grad_norm": 30517.947265625,
      "learning_rate": 0.00026688804554079695,
      "loss": 2.7191,
      "step": 350
    },
    {
      "epoch": 0.3415559772296015,
      "grad_norm": 37488.76171875,
      "learning_rate": 0.00026593927893738136,
      "loss": 2.7367,
      "step": 360
    },
    {
      "epoch": 0.3510436432637571,
      "grad_norm": 28555.7265625,
      "learning_rate": 0.00026499051233396583,
      "loss": 2.625,
      "step": 370
    },
    {
      "epoch": 0.3605313092979127,
      "grad_norm": 32605.716796875,
      "learning_rate": 0.00026404174573055024,
      "loss": 2.6168,
      "step": 380
    },
    {
      "epoch": 0.3700189753320683,
      "grad_norm": 48836.1328125,
      "learning_rate": 0.0002630929791271347,
      "loss": 2.654,
      "step": 390
    },
    {
      "epoch": 0.3795066413662239,
      "grad_norm": 46018.9296875,
      "learning_rate": 0.0002621442125237191,
      "loss": 2.6146,
      "step": 400
    },
    {
      "epoch": 0.3889943074003795,
      "grad_norm": 43298.85546875,
      "learning_rate": 0.0002611954459203036,
      "loss": 2.7042,
      "step": 410
    },
    {
      "epoch": 0.3984819734345351,
      "grad_norm": 56624.6484375,
      "learning_rate": 0.000260246679316888,
      "loss": 2.9666,
      "step": 420
    },
    {
      "epoch": 0.4079696394686907,
      "grad_norm": 48075.43359375,
      "learning_rate": 0.0002592979127134725,
      "loss": 2.4726,
      "step": 430
    },
    {
      "epoch": 0.4174573055028463,
      "grad_norm": 32080.43359375,
      "learning_rate": 0.0002583491461100569,
      "loss": 2.4701,
      "step": 440
    },
    {
      "epoch": 0.4269449715370019,
      "grad_norm": 48359.75390625,
      "learning_rate": 0.00025740037950664136,
      "loss": 2.6368,
      "step": 450
    },
    {
      "epoch": 0.4364326375711575,
      "grad_norm": 46632.26171875,
      "learning_rate": 0.00025645161290322577,
      "loss": 3.0762,
      "step": 460
    },
    {
      "epoch": 0.4459203036053131,
      "grad_norm": 32467.28515625,
      "learning_rate": 0.00025550284629981024,
      "loss": 2.6233,
      "step": 470
    },
    {
      "epoch": 0.45540796963946867,
      "grad_norm": 44543.6953125,
      "learning_rate": 0.00025455407969639465,
      "loss": 2.5112,
      "step": 480
    },
    {
      "epoch": 0.4648956356736243,
      "grad_norm": 34669.7421875,
      "learning_rate": 0.0002536053130929791,
      "loss": 2.6395,
      "step": 490
    },
    {
      "epoch": 0.47438330170777987,
      "grad_norm": 43604.9921875,
      "learning_rate": 0.00025265654648956354,
      "loss": 2.8407,
      "step": 500
    },
    {
      "epoch": 0.4838709677419355,
      "grad_norm": 37956.82421875,
      "learning_rate": 0.00025170777988614795,
      "loss": 2.369,
      "step": 510
    },
    {
      "epoch": 0.49335863377609107,
      "grad_norm": 43986.1328125,
      "learning_rate": 0.0002507590132827324,
      "loss": 2.7539,
      "step": 520
    },
    {
      "epoch": 0.5028462998102466,
      "grad_norm": 39571.7265625,
      "learning_rate": 0.00024981024667931683,
      "loss": 2.7079,
      "step": 530
    },
    {
      "epoch": 0.5123339658444023,
      "grad_norm": 25566.3125,
      "learning_rate": 0.0002488614800759013,
      "loss": 2.7699,
      "step": 540
    },
    {
      "epoch": 0.5218216318785579,
      "grad_norm": 35077.76171875,
      "learning_rate": 0.00024791271347248577,
      "loss": 2.6701,
      "step": 550
    },
    {
      "epoch": 0.5313092979127134,
      "grad_norm": 36112.42578125,
      "learning_rate": 0.0002469639468690702,
      "loss": 2.8775,
      "step": 560
    },
    {
      "epoch": 0.540796963946869,
      "grad_norm": 40120.73046875,
      "learning_rate": 0.00024601518026565465,
      "loss": 2.5516,
      "step": 570
    },
    {
      "epoch": 0.5502846299810247,
      "grad_norm": 53883.6640625,
      "learning_rate": 0.00024506641366223907,
      "loss": 2.6384,
      "step": 580
    },
    {
      "epoch": 0.5597722960151803,
      "grad_norm": 33984.17578125,
      "learning_rate": 0.0002441176470588235,
      "loss": 2.5499,
      "step": 590
    },
    {
      "epoch": 0.5692599620493358,
      "grad_norm": 43139.21484375,
      "learning_rate": 0.00024316888045540795,
      "loss": 2.8051,
      "step": 600
    },
    {
      "epoch": 0.5787476280834914,
      "grad_norm": 48365.90234375,
      "learning_rate": 0.0002422201138519924,
      "loss": 2.5045,
      "step": 610
    },
    {
      "epoch": 0.5882352941176471,
      "grad_norm": 53100.74609375,
      "learning_rate": 0.00024127134724857683,
      "loss": 2.5316,
      "step": 620
    },
    {
      "epoch": 0.5977229601518027,
      "grad_norm": 41934.68359375,
      "learning_rate": 0.00024032258064516125,
      "loss": 2.6017,
      "step": 630
    },
    {
      "epoch": 0.6072106261859582,
      "grad_norm": 32078.84765625,
      "learning_rate": 0.00023937381404174571,
      "loss": 2.62,
      "step": 640
    },
    {
      "epoch": 0.6166982922201139,
      "grad_norm": 52523.7578125,
      "learning_rate": 0.00023842504743833016,
      "loss": 2.5485,
      "step": 650
    },
    {
      "epoch": 0.6261859582542695,
      "grad_norm": 33042.6875,
      "learning_rate": 0.0002374762808349146,
      "loss": 2.6211,
      "step": 660
    },
    {
      "epoch": 0.635673624288425,
      "grad_norm": 36320.71484375,
      "learning_rate": 0.00023652751423149904,
      "loss": 2.6927,
      "step": 670
    },
    {
      "epoch": 0.6451612903225806,
      "grad_norm": 51923.28515625,
      "learning_rate": 0.00023557874762808348,
      "loss": 2.7255,
      "step": 680
    },
    {
      "epoch": 0.6546489563567363,
      "grad_norm": 58207.76171875,
      "learning_rate": 0.00023462998102466792,
      "loss": 2.8782,
      "step": 690
    },
    {
      "epoch": 0.6641366223908919,
      "grad_norm": 51462.17578125,
      "learning_rate": 0.00023368121442125236,
      "loss": 2.4841,
      "step": 700
    },
    {
      "epoch": 0.6736242884250474,
      "grad_norm": 49118.6484375,
      "learning_rate": 0.00023273244781783678,
      "loss": 2.797,
      "step": 710
    },
    {
      "epoch": 0.683111954459203,
      "grad_norm": 31429.275390625,
      "learning_rate": 0.00023178368121442122,
      "loss": 2.6122,
      "step": 720
    },
    {
      "epoch": 0.6925996204933587,
      "grad_norm": 46235.88671875,
      "learning_rate": 0.00023083491461100566,
      "loss": 2.5496,
      "step": 730
    },
    {
      "epoch": 0.7020872865275142,
      "grad_norm": 44399.54296875,
      "learning_rate": 0.0002298861480075901,
      "loss": 2.6035,
      "step": 740
    },
    {
      "epoch": 0.7115749525616698,
      "grad_norm": 54712.93359375,
      "learning_rate": 0.00022893738140417457,
      "loss": 2.5971,
      "step": 750
    },
    {
      "epoch": 0.7210626185958254,
      "grad_norm": 71849.578125,
      "learning_rate": 0.000227988614800759,
      "loss": 2.8146,
      "step": 760
    },
    {
      "epoch": 0.7305502846299811,
      "grad_norm": 28588.4453125,
      "learning_rate": 0.00022703984819734345,
      "loss": 2.4522,
      "step": 770
    },
    {
      "epoch": 0.7400379506641366,
      "grad_norm": 48430.8125,
      "learning_rate": 0.0002260910815939279,
      "loss": 2.5185,
      "step": 780
    },
    {
      "epoch": 0.7495256166982922,
      "grad_norm": 62622.03515625,
      "learning_rate": 0.0002251423149905123,
      "loss": 2.7323,
      "step": 790
    },
    {
      "epoch": 0.7590132827324478,
      "grad_norm": 29723.611328125,
      "learning_rate": 0.00022419354838709675,
      "loss": 2.6328,
      "step": 800
    },
    {
      "epoch": 0.7685009487666035,
      "grad_norm": 37353.69921875,
      "learning_rate": 0.0002232447817836812,
      "loss": 2.5116,
      "step": 810
    },
    {
      "epoch": 0.777988614800759,
      "grad_norm": 27261.109375,
      "learning_rate": 0.00022229601518026563,
      "loss": 2.3822,
      "step": 820
    },
    {
      "epoch": 0.7874762808349146,
      "grad_norm": 48481.91015625,
      "learning_rate": 0.00022134724857685007,
      "loss": 2.6031,
      "step": 830
    },
    {
      "epoch": 0.7969639468690702,
      "grad_norm": 67423.5234375,
      "learning_rate": 0.0002203984819734345,
      "loss": 2.5134,
      "step": 840
    },
    {
      "epoch": 0.8064516129032258,
      "grad_norm": 38647.5234375,
      "learning_rate": 0.00021944971537001895,
      "loss": 2.8003,
      "step": 850
    },
    {
      "epoch": 0.8159392789373814,
      "grad_norm": 44392.046875,
      "learning_rate": 0.00021850094876660342,
      "loss": 2.3719,
      "step": 860
    },
    {
      "epoch": 0.825426944971537,
      "grad_norm": 44738.7421875,
      "learning_rate": 0.00021755218216318786,
      "loss": 2.7654,
      "step": 870
    },
    {
      "epoch": 0.8349146110056926,
      "grad_norm": 50119.94140625,
      "learning_rate": 0.00021660341555977228,
      "loss": 2.8016,
      "step": 880
    },
    {
      "epoch": 0.8444022770398482,
      "grad_norm": 44784.31640625,
      "learning_rate": 0.00021565464895635672,
      "loss": 2.7616,
      "step": 890
    },
    {
      "epoch": 0.8538899430740038,
      "grad_norm": 38396.875,
      "learning_rate": 0.00021470588235294116,
      "loss": 2.3606,
      "step": 900
    },
    {
      "epoch": 0.8633776091081594,
      "grad_norm": 44417.20703125,
      "learning_rate": 0.0002137571157495256,
      "loss": 2.7227,
      "step": 910
    },
    {
      "epoch": 0.872865275142315,
      "grad_norm": 58098.26953125,
      "learning_rate": 0.00021280834914611004,
      "loss": 2.8431,
      "step": 920
    },
    {
      "epoch": 0.8823529411764706,
      "grad_norm": 39244.91796875,
      "learning_rate": 0.00021185958254269448,
      "loss": 2.6659,
      "step": 930
    },
    {
      "epoch": 0.8918406072106262,
      "grad_norm": 48443.859375,
      "learning_rate": 0.00021091081593927892,
      "loss": 2.6676,
      "step": 940
    },
    {
      "epoch": 0.9013282732447818,
      "grad_norm": 34485.37890625,
      "learning_rate": 0.00020996204933586334,
      "loss": 2.5023,
      "step": 950
    },
    {
      "epoch": 0.9108159392789373,
      "grad_norm": 51009.23046875,
      "learning_rate": 0.00020901328273244778,
      "loss": 2.4266,
      "step": 960
    },
    {
      "epoch": 0.920303605313093,
      "grad_norm": 52575.55859375,
      "learning_rate": 0.00020806451612903225,
      "loss": 2.6411,
      "step": 970
    },
    {
      "epoch": 0.9297912713472486,
      "grad_norm": 62793.13671875,
      "learning_rate": 0.0002071157495256167,
      "loss": 2.5471,
      "step": 980
    },
    {
      "epoch": 0.9392789373814042,
      "grad_norm": 36921.1171875,
      "learning_rate": 0.00020616698292220113,
      "loss": 2.3199,
      "step": 990
    },
    {
      "epoch": 0.9487666034155597,
      "grad_norm": 53267.47265625,
      "learning_rate": 0.00020521821631878557,
      "loss": 2.531,
      "step": 1000
    },
    {
      "epoch": 0.9582542694497154,
      "grad_norm": 48005.2734375,
      "learning_rate": 0.00020426944971537,
      "loss": 2.7004,
      "step": 1010
    },
    {
      "epoch": 0.967741935483871,
      "grad_norm": 62444.7734375,
      "learning_rate": 0.00020332068311195445,
      "loss": 2.512,
      "step": 1020
    },
    {
      "epoch": 0.9772296015180265,
      "grad_norm": 59836.7109375,
      "learning_rate": 0.00020237191650853887,
      "loss": 2.4351,
      "step": 1030
    },
    {
      "epoch": 0.9867172675521821,
      "grad_norm": 40573.78125,
      "learning_rate": 0.0002014231499051233,
      "loss": 2.4179,
      "step": 1040
    },
    {
      "epoch": 0.9962049335863378,
      "grad_norm": 44080.7578125,
      "learning_rate": 0.00020047438330170775,
      "loss": 2.398,
      "step": 1050
    }
  ],
  "logging_steps": 10,
  "max_steps": 3162,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5794728978677760.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
